<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="VestJin---靳马珏"><meta name="keywords" content="记录 博客 日志"><meta name="description" content="太好了！下面是你请求的关于「高校招生数据分析平台」的完整内容，包括项目文档、简历描述、项目讲解稿，以及核心技术模块讲解。   📄 一、完整项目文档：《高校招生数据分析与可视化平台》  ✅ 1. 项目简介 本项目旨在通过自动化方式爬取全国各高校近年录取分数线、招生计划等公开数据，对数据进行清洗、存储与分析，并通过可视化图表形式展示不同高校、不同专业的录取趋势，为考生与家长提供数据支持和参考。"><meta property="og:type" content="article"><meta property="og:title" content="高校招生数据分析与可视化平台"><meta property="og:url" content="http://blog.jinmajue.site/posts/97171005/index.html"><meta property="og:site_name" content="靳马珏日志"><meta property="og:description" content="太好了！下面是你请求的关于「高校招生数据分析平台」的完整内容，包括项目文档、简历描述、项目讲解稿，以及核心技术模块讲解。   📄 一、完整项目文档：《高校招生数据分析与可视化平台》  ✅ 1. 项目简介 本项目旨在通过自动化方式爬取全国各高校近年录取分数线、招生计划等公开数据，对数据进行清洗、存储与分析，并通过可视化图表形式展示不同高校、不同专业的录取趋势，为考生与家长提供数据支持和参考。"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2024-11-14T10:13:32.000Z"><meta property="article:modified_time" content="2025-04-14T15:16:26.278Z"><meta property="article:author" content="VestJin---靳马珏"><meta property="article:tag" content="记录 博客 日志"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>高校招生数据分析与可视化平台 - 靳马珏日志</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"blog.jinmajue.site",root:"/",version:"1.9.8",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:"§"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:{measurement_id:null},tencent:{sid:null,cid:null},leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1},umami:{src:null,website_id:null,domains:null,start_time:"2023-08-30T00:00:00.000Z",token:null,api_server:null}},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="靳马珏日志" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>靳马珏的网络日志</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="高校招生数据分析与可视化平台"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-11-14 18:13" pubdate>2024年11月14日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.3k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 20 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">高校招生数据分析与可视化平台</h1><div class="markdown-body"><hr><p>太好了！下面是你请求的关于「高校招生数据分析平台」的完整内容，包括项目文档、简历描述、项目讲解稿，以及核心技术模块讲解。</p><hr><h2 id="一-完整项目文档高校招生数据分析与可视化平台"><a class="markdownIt-Anchor" href="#一-完整项目文档高校招生数据分析与可视化平台"></a> 📄 一、完整项目文档：《高校招生数据分析与可视化平台》</h2><h3 id="1-项目简介"><a class="markdownIt-Anchor" href="#1-项目简介"></a> ✅ 1. 项目简介</h3><p>本项目旨在通过自动化方式爬取全国各高校近年录取分数线、招生计划等公开数据，对数据进行清洗、存储与分析，并通过可视化图表形式展示不同高校、不同专业的录取趋势，为考生与家长提供数据支持和参考。</p><hr><h3 id="2-项目目标与功能模块"><a class="markdownIt-Anchor" href="#2-项目目标与功能模块"></a> ✅ 2. 项目目标与功能模块</h3><h4 id="项目目标"><a class="markdownIt-Anchor" href="#项目目标"></a> 🎯 项目目标：</h4><ul><li>聚合各省市高校历年录取数据</li><li>提供高校/专业/地区多维度查询分析</li><li>可视化展示趋势、对比、分布图表</li></ul><h4 id="功能模块划分"><a class="markdownIt-Anchor" href="#功能模块划分"></a> 🧩 功能模块划分：</h4><table><thead><tr><th>模块</th><th>功能说明</th></tr></thead><tbody><tr><td>数据爬取</td><td>从阳光高考、各省教育考试院官网等抓取历年招生录取数据</td></tr><tr><td>数据处理</td><td>清洗、格式统一、缺失填补、异常值处理</td></tr><tr><td>数据分析</td><td>分数线趋势、招生人数变化、专业热度等分析</td></tr><tr><td>数据可视化</td><td>地图分布、折线图、柱状图、词云等形式展示分析结果</td></tr><tr><td>查询接口</td><td>支持通过高校、地区、专业、年份进行查询</td></tr></tbody></table><hr><h3 id="3-技术架构图"><a class="markdownIt-Anchor" href="#3-技术架构图"></a> ✅ 3. 技术架构图</h3><figure class="highlight sas"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs SAS">          ┌────────────┐<br>          │  爬虫模块   │ ← requests + lxml<br>          └────┬───────┘<br>               ↓<br>        ┌──────────────┐<br>        │ 数据清洗处理 │ ← pandas<br>        └────┬─────────┘<br>             ↓<br>      ┌────────────┐<br>      │ 数据存储层 │ ← SQLite / CSV（轻量级）<br>      └────┬───────┘<br>           ↓<br> ┌───────────────────────┐<br> │ Flask 后端API服务     │<br> └────┬──────────────────┘<br>      ↓<br>┌────────────┐     ┌─────────────────────┐<br>│ 前端页面展示 │ ← HTML+JS+Echarts/Folium │<br>└────────────┘     └─────────────────────┘<br></code></pre></td></tr></tbody></table></figure><hr><h3 id="4-技术栈详解"><a class="markdownIt-Anchor" href="#4-技术栈详解"></a> ✅ 4. 技术栈详解</h3><table><thead><tr><th>技术</th><th>作用</th></tr></thead><tbody><tr><td><code>requests</code></td><td>发送网络请求，抓取网页HTML</td></tr><tr><td><code>lxml / re</code></td><td>页面解析，提取目标数据</td></tr><tr><td><code>pandas</code></td><td>数据清洗、统计分析</td></tr><tr><td><code>Flask</code></td><td>提供API与数据接口</td></tr><tr><td><code>Echarts</code></td><td>折线图、柱状图、词云展示</td></tr><tr><td><code>Folium</code></td><td>地理地图可视化（省份录取对比）</td></tr><tr><td><code>SQLite/CSV</code></td><td>存储结构化招生信息</td></tr></tbody></table><hr><h3 id="5-示例可视化效果"><a class="markdownIt-Anchor" href="#5-示例可视化效果"></a> ✅ 5. 示例可视化效果</h3><ul><li>折线图：某高校某专业5年录取分数线趋势</li><li>柱状图：省内各高校招生计划对比</li><li>地图热力图：全国各省录取分数平均值</li><li>词云图：热门专业词频展示</li></ul><hr><h2 id="️-二-项目描述含技术亮点"><a class="markdownIt-Anchor" href="#️-二-项目描述含技术亮点"></a> ✍️ 二、项目描述（含技术亮点）</h2><p><strong>项目概述：</strong><br>通过爬虫抓取全国各高校近年录取数据，构建数据分析与可视化平台，帮助用户快速了解不同学校和专业的录取趋势。</p><p><strong>技术要点：</strong></p><ul><li>使用 <code>requests + lxml</code> 构建爬虫模块，抓取阳光高考等权威平台数据</li><li>基于 <code>pandas</code> 完成数据清洗与趋势分析</li><li>使用 <code>Flask</code> 搭建后端服务，提供数据接口</li><li>通过 <code>Echarts</code> 和 <code>Folium</code> 实现分数趋势、地理分布等可视化展示</li><li>支持根据高校、专业、地区等多条件组合查询</li></ul><p><strong>项目亮点：</strong></p><ul><li>数据多维度对比：支持按省、校、专业、年份等维度分析</li><li>可视化丰富：集成地图、趋势图、柱状图、词云等交互式图表</li><li>技术栈清晰，模块解耦，便于后期拓展与维护</li></ul><hr><hr><h2 id="三-核心技术模块原理讲解"><a class="markdownIt-Anchor" href="#三-核心技术模块原理讲解"></a> 🧠 三、核心技术模块原理讲解</h2><h3 id="数据爬虫模块requests-lxml"><a class="markdownIt-Anchor" href="#数据爬虫模块requests-lxml"></a> 🔧 数据爬虫模块（requests + lxml）</h3><p>从各省考试院、高校官网、阳光高考网等公开网站中自动化抓取包含<strong>录取分数线、招生计划、专业信息等</strong>结构化数据。</p><ul><li>利用 <code>requests</code> 发送 GET 请求获取高校招生网页内容</li><li>使用 <code>lxml.etree</code> 中的 XPath 提取表格数据（如年份、分数线、专业）</li><li>针对各省结构不同，编写差异化解析器</li><li>保存为结构化 CSV 或写入数据库</li></ul><h3 id="数据清洗与分析模块pandas"><a class="markdownIt-Anchor" href="#数据清洗与分析模块pandas"></a> 🔧 数据清洗与分析模块（pandas）</h3><ul><li>缺失值处理、字段标准化（如“软件工程”与“软件工程（本科）”统一）</li><li>分数转化（如按文理科、一本二本划分）</li><li>分析处理如：<ul><li>按年份平均分趋势</li><li>专业热度词频统计</li><li>招生计划增长率分析等</li></ul></li></ul><h3 id="可视化模块echarts-folium"><a class="markdownIt-Anchor" href="#可视化模块echarts-folium"></a> 🔧 可视化模块（Echarts + Folium）</h3><ul><li>折线图：分析趋势（年份 vs 分数）</li><li>柱状图：高校/专业对比展示</li><li>地图热力图：不同省市录取分数平均值展示（Folium 支持 GeoJSON）</li><li>词云：热门专业关键词可视化</li></ul><hr><h2><a class="markdownIt-Anchor" href="#"></a></h2><p>爬虫模块优化是确保数据抓取更高效、稳定并避免封禁的重要环节。通过以下几种优化策略，可以提高爬虫的性能和健壮性。下面是对爬虫模块优化的详细介绍，涵盖了不同技术和策略的应用：</p><hr><h2 id="爬虫模块优化方法"><a class="markdownIt-Anchor" href="#爬虫模块优化方法"></a> 🔧 爬虫模块优化方法</h2><h3 id="1-请求头伪装与反爬机制绕过"><a class="markdownIt-Anchor" href="#1-请求头伪装与反爬机制绕过"></a> 1. <strong>请求头伪装与反爬机制绕过</strong></h3><p>为了避免因频繁请求导致 IP 被封禁，或者爬虫被识别为非正常访问，爬虫请求需要伪装成正常用户的浏览行为。</p><ul><li><strong>User-Agent伪装</strong>：使用常见的浏览器 User-Agent 来模拟浏览器请求。</li><li><strong>Referer与Origin伪装</strong>：模拟页面访问的来源，避免因缺少<code>Referer</code>或者<code>Origin</code>信息而被识别为爬虫。</li><li><strong>Cookies与Session保持</strong>：很多网站通过 Cookie 判断用户是否为人类。模拟浏览器行为，维护请求会话（<code>requests.Session</code>），每次请求带上 Cookie 和 Session 信息，模拟长期浏览器会话。</li></ul><h4 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><br>headers = {<br>    <span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'</span>,<br>    <span class="hljs-string">'Referer'</span>: <span class="hljs-string">'https://example.com'</span>,<br>    <span class="hljs-string">'Origin'</span>: <span class="hljs-string">'https://example.com'</span><br>}<br>session = requests.Session()<br>response = session.get(<span class="hljs-string">'https://example.com'</span>, headers=headers)<br></code></pre></td></tr></tbody></table></figure><hr><h3 id="2-增加请求间隔与随机延时"><a class="markdownIt-Anchor" href="#2-增加请求间隔与随机延时"></a> 2. <strong>增加请求间隔与随机延时</strong></h3><p>爬虫的请求频率过高容易导致服务器拒绝服务或封锁 IP。通过设置合理的间隔时间以及随机延时，可以降低爬虫被识别为攻击行为的风险。</p><ul><li><strong>静态延时</strong>：每次请求之间加上固定时间（如 1 秒）。</li><li><strong>动态延时</strong>：根据一定范围随机延时（例如在 1 到 3 秒之间随机等待）。</li></ul><h4 id="示例-2"><a class="markdownIt-Anchor" href="#示例-2"></a> 示例：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><br>time.sleep(random.uniform(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))  <span class="hljs-comment"># 每次请求之间随机延时1到3秒</span><br></code></pre></td></tr></tbody></table></figure><hr><h3 id="3-代理池的使用"><a class="markdownIt-Anchor" href="#3-代理池的使用"></a> 3. <strong>代理池的使用</strong></h3><p>为了避免爬虫 IP 被封禁，可以使用代理池技术。代理池通过切换不同的代理 IP 进行请求，可以有效分散请求的来源，降低单一 IP 被封禁的风险。</p><ul><li><strong>代理池的构建</strong>：可以通过第三方 API 提供的代理池，或者自建代理池。</li><li><strong>代理池的轮换</strong>：定期或按需更换代理，避免频繁使用同一个 IP。</li></ul><h4 id="示例使用-requests-和代理池"><a class="markdownIt-Anchor" href="#示例使用-requests-和代理池"></a> 示例（使用 <code>requests</code> 和代理池）：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br>proxies = [<br>    <span class="hljs-string">'http://proxy1.com'</span>,<br>    <span class="hljs-string">'http://proxy2.com'</span>,<br>    <span class="hljs-string">'http://proxy3.com'</span><br>]<br><br>proxy = {<span class="hljs-string">'http'</span>: random.choice(proxies), <span class="hljs-string">'https'</span>: random.choice(proxies)}<br>response = requests.get(<span class="hljs-string">'https://example.com'</span>, proxies=proxy)<br></code></pre></td></tr></tbody></table></figure><hr><h3 id="4-使用异步爬虫与并发请求"><a class="markdownIt-Anchor" href="#4-使用异步爬虫与并发请求"></a> 4. <strong>使用异步爬虫与并发请求</strong></h3><p>对于大量数据的抓取，传统的同步爬虫可能效率较低。使用异步请求（如 <code>aiohttp</code> 或 <code>requests-futures</code>）和并发请求可以显著提高抓取速度。</p><ul><li><strong>异步爬虫</strong>：使用 <code>asyncio</code> 和 <code>aiohttp</code> 来并发请求，避免阻塞等待。</li><li><strong>并发请求</strong>：通过多线程或多进程（如 <code>concurrent.futures</code> 或 <code>multiprocessing</code>）进行并行抓取。</li></ul><h4 id="示例使用-aiohttp-异步请求"><a class="markdownIt-Anchor" href="#示例使用-aiohttp-异步请求"></a> 示例（使用 <code>aiohttp</code> 异步请求）：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> aiohttp<br><span class="hljs-keyword">import</span> asyncio<br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">fetch</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.get(url) <span class="hljs-keyword">as</span> response:<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> response.text()<br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    url = <span class="hljs-string">'https://example.com'</span><br>    html = <span class="hljs-keyword">await</span> fetch(url)<br>    <span class="hljs-built_in">print</span>(html)<br><br>loop = asyncio.get_event_loop()<br>loop.run_until_complete(main())<br></code></pre></td></tr></tbody></table></figure><hr><h3 id="5-捕获异常与重试机制"><a class="markdownIt-Anchor" href="#5-捕获异常与重试机制"></a> 5. <strong>捕获异常与重试机制</strong></h3><p>爬虫请求过程中，可能会因为网络问题、服务器问题等导致请求失败。通过异常处理和重试机制，可以提高爬虫的健壮性。</p><ul><li><strong>捕获异常</strong>：通过 <code>try...except</code> 捕获请求错误（如 <code>Timeout</code>, <code>ConnectionError</code>）。</li><li><strong>重试机制</strong>：对于失败的请求，进行定时重试，并限制最大重试次数，避免死循环。</li></ul><h4 id="示例重试机制"><a class="markdownIt-Anchor" href="#示例重试机制"></a> 示例（重试机制）：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_page</span>(<span class="hljs-params">url, retries=<span class="hljs-number">3</span></span>):<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(retries):<br>        <span class="hljs-keyword">try</span>:<br>            response = requests.get(url, timeout=<span class="hljs-number">5</span>)<br>            <span class="hljs-keyword">return</span> response<br>        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Error occurred: <span class="hljs-subst">{e}</span>"</span>)<br>            sleep(<span class="hljs-number">3</span>)  <span class="hljs-comment"># 等待3秒后重试</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>url = <span class="hljs-string">'https://example.com'</span><br>response = get_page(url)<br><span class="hljs-keyword">if</span> response:<br>    <span class="hljs-built_in">print</span>(response.content)<br></code></pre></td></tr></tbody></table></figure><hr><h3 id="6-防止重复抓取与数据去重"><a class="markdownIt-Anchor" href="#6-防止重复抓取与数据去重"></a> 6. <strong>防止重复抓取与数据去重</strong></h3><p>爬虫过程中，经常会碰到重复抓取相同网页或内容的情况。使用数据去重机制避免无意义的重复请求。</p><ul><li><strong>URL去重</strong>：可以使用 <code>set</code> 数据结构，去除已访问过的 URL。</li><li><strong>内容去重</strong>：对于页面内容相似的情况（如动态加载的内容），可以通过内容的哈希值判断是否已抓取过。</li></ul><h4 id="示例去重"><a class="markdownIt-Anchor" href="#示例去重"></a> 示例（去重）：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">visited_urls = <span class="hljs-built_in">set</span>()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">crawl</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-keyword">if</span> url <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited_urls:<br>        visited_urls.add(url)<br>        <span class="hljs-comment"># 执行爬取操作</span><br></code></pre></td></tr></tbody></table></figure><hr><h3 id="7-动态页面数据抓取"><a class="markdownIt-Anchor" href="#7-动态页面数据抓取"></a> 7. <strong>动态页面数据抓取</strong></h3><p>许多网站使用 JavaScript 动态加载数据，这种情况下直接抓取 HTML 代码将无法获取实际数据。可以使用 <code>selenium</code> 或 <code>playwright</code> 模拟浏览器行为，抓取动态生成的数据。</p><ul><li><strong>Selenium</strong>：自动化操作浏览器，支持抓取 JavaScript 渲染后的内容。</li><li><strong>Playwright</strong>：比 <code>selenium</code> 更轻量、高效的自动化浏览器工具。</li></ul><h4 id="示例使用-selenium"><a class="markdownIt-Anchor" href="#示例使用-selenium"></a> 示例（使用 <code>selenium</code>）：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><br>driver = webdriver.Chrome()<br>driver.get(<span class="hljs-string">"https://example.com"</span>)<br>page_source = driver.page_source  <span class="hljs-comment"># 获取渲染后的页面内容</span><br>driver.quit()<br></code></pre></td></tr></tbody></table></figure><hr><h3 id="8-爬虫调度与分布式抓取"><a class="markdownIt-Anchor" href="#8-爬虫调度与分布式抓取"></a> 8. <strong>爬虫调度与分布式抓取</strong></h3><p>对于大规模数据抓取，可以考虑将爬虫分布式化，提升爬取速度和覆盖面。可以使用调度框架如 <code>Celery</code>、<code>Scrapy</code> 的分布式功能来调度任务。</p><ul><li><strong>分布式爬虫</strong>：通过多台机器并行抓取，提高数据采集的速度。</li><li><strong>任务调度</strong>：定期爬取最新数据，并可以对爬取过程进行监控与日志记录。</li></ul><hr></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/projects/" class="category-chain-item">projects</a></span></span></div></div><div class="license-box my-3"><div class="license-title"><div>高校招生数据分析与可视化平台</div><div>http://blog.jinmajue.site/posts/97171005/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>VestJin---靳马珏</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年11月14日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-cc-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/540c6e02/" title="如何阅读科研论文"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">如何阅读科研论文</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/6536aa06/" title="编译原理概念速查"><span class="hidden-mobile">编译原理概念速查</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"boxy-light",window.UtterancesThemeLight="boxy-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","Code-Mist/fluid-comment"),e.setAttribute("issue-term","pathname"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js",(function(){mermaid.initialize({theme:"default"}),Fluid.utils.listenDOMLoaded((function(){Fluid.events.registerRefreshCallback((function(){"mermaid"in window&&mermaid.init()}))}))}))</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>